{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Clapper Rails and King Rails Based on their Kek Calls\n",
    "\n",
    "This project will analyze acoustic markers derived from audio recordings of Clapper Rails and King Rails in an attempt to classify the species.  \n",
    "Sample sounds from these call can be listened to at The Cornell Lab:\n",
    " - Clapper Rail Sounds: https://www.allaboutbirds.org/guide/Clapper_Rail/sounds\n",
    " - King Rail Sounds: https://www.allaboutbirds.org/guide/King_Rail/sounds\n",
    "\n",
    "Original work on this dataset is documented at the Wiley Online Library: https://onlinelibrary.wiley.com/doi/10.1002/ece3.4711  \n",
    "A copy of this research is also included in this git repository as \"Ecology and Evolution - 2018 - Stiffler.pdf\"\n",
    "\n",
    "During this analysis we will review the following questions:\n",
    " - Can we reproduce the basic findings regarding optimal machine learning models for this classification?\n",
    " - Are there improvements that can be made in the outcomes?\n",
    "\n",
    "https://github.com/carl-schick-ds/rails.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Setup\n",
    "Import needed libraries.  Unless otherwise noted, all libraries are available in the baseline conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Data Collection\n",
    "Data collection was not required for this project since the original dataset is available online in CSV format and is included in this repository as \"KIRACLRA.csv\".  \n",
    "I reached out to the original researches in an attempt to obtain the source audio recordings that were used to produce the audio markers in the dataset, but those recordings are no longer available.  \n",
    "\n",
    "It's feasible that improvements could be made to the classification model by using different audio markers, but this is beyond the scope of this analysis and, in any regard, is not possible due to the unavailability of the source audio recordings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CSVs\n",
    "Load the data from the csv files and run a quick review of the data for validity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rails_df = pd.read_csv('KIRACLRA.csv')\n",
    "rails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rails_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Generate descriptive statistics for both the Clapper Rail and King Rail recordings.  \n",
    "These were compared back to the original research to confirm we are starting from the same place.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clapper Rails Descriptive Statistics\")\n",
    "display(rails_df[rails_df['Species'] == 'CLRA'].describe().round(decimals=0).astype(int))\n",
    "print(\"King Rails Descriptive Statistics\")\n",
    "display(rails_df[rails_df['Species'] == 'KIRA'].describe().round(decimals=0).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the target column, Species, review the counts, rename the values, and reset the column as a categorical type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define our Categorical Dtype in order to ensure the Clapper Species is the positive value during classification\n",
    "species_cat = CategoricalDtype(categories=['King', 'Clapper'], ordered=True)  \n",
    "\n",
    "print(rails_df['Species'].value_counts())\n",
    "rails_df['Species'] = rails_df['Species'].apply(lambda x: 'Clapper' if x == 'CLRA' else 'King')\n",
    "rails_df['Species'] = rails_df['Species'].astype(species_cat)\n",
    "print(rails_df['Species'].value_counts())\n",
    "# print()\n",
    "# print(rails_df['Species'].cat.codes)\n",
    "print()\n",
    "display(rails_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Review the correlation of the parameters to determine if any parameters can be dropped in order to simply the models.  \n",
    "Generate both a correlation table and a heatmap.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = rails_df.corr()\n",
    "display(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the self-correlation cells (the diaganols) to zero to minimize their prominence during visual review\n",
    "np.fill_diagonal(corr.values, 0)\n",
    "\n",
    "# Set the palette to 'coolwarm' and the min/max to the extreme ends of valid correlation values\n",
    "colormap = sns.color_palette(\"coolwarm\")\n",
    "vmin, vmax = (-1, 1)\n",
    "\n",
    "# Display the heatmap\n",
    "sns.heatmap(corr, center=(vmin + vmax) / 2, vmin=vmin, vmax=vmax, cmap=colormap)\n",
    "'';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the correlation table and the heatmap indicate a strong correlation between the Bandwidth (BW) markers and one of the Frequency ranges.  \n",
    "Specifically, `IGR BW (Hz)` is highly correlated with `Q3 Freq Hz` (*r* $\\approx$ .75) and `BW 90% (Hz)` is highly correlated with `Freq 95% (Hz)` (*r* $\\approx$ .89)  \n",
    "\n",
    "<mark>Is this next statement true?  I ran most of the models with and without the Bandwidth columns and the results were similar or worse when they were included.  \n",
    "Are there considerations other than the *r* value that I should be reviewing for the claims below?</mark>  \n",
    "\n",
    "Parameters with correlations above .70 - .75 will have a negligible impact on the model results since their values are appropriately accounted for in another parameter.  At times, their inclusion could actually produce worse outcomes since they can add unnecessary noise to the model generation.  For this reason, we will drop both of the Bandwidth (BW) markers from the dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Drop the Bandwidth (BW) columns due to their high correlation with other parameters.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rails_df.drop(['IQR BW (Hz)', 'BW 90% (Hz)'], axis=1, inplace=True)\n",
    "display(rails_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Parameter Realtionships with Species Classification\n",
    "The relationship of each parameter with the Species classification is visualized in a variety of formats: historgrams, boxplots, violinplots, and scatterplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = rails_df.drop('Species', axis=1).columns.to_list()\n",
    "\n",
    "fig, axes = plt.subplots(5,5, figsize=(25,25))\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "for i in range(len(feature_columns)):\n",
    "    sns.histplot(data=rails_df, x=feature_columns[i], bins = 30, hue='Species', ax=axes[0,i])\n",
    "    sns.kdeplot(data=rails_df, x=feature_columns[i], hue='Species', ax=axes[1,i])\n",
    "    sns.boxplot(data=rails_df, x=feature_columns[i], y='Species', ax=axes[2,i])\n",
    "    sns.violinplot(data=rails_df, x=feature_columns[i], y='Species', hue='Species', legend=False, ax=axes[3,i])\n",
    "    sns.scatterplot(data=rails_df, x=feature_columns[i], y='Species', hue='Species', legend=False, ax=axes[4,i])\n",
    "\n",
    "for i in range(len(axes[3])):\n",
    "    axes[3,i].legend().remove()\n",
    "'';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>\n",
    "I could use some help interpreting the above visualizations.  At a high level, it looks like there is a lot of overlap between the data values and the Species class, which would make modeling difficult.  The kdeplots show some bright spots, where some parameters (Freq 5% and Freq 95% in particular) clearly have values with higher occurrences in one species vs. another.  \n",
    "<br>\n",
    "<br>\n",
    "But in general, how should I be interpreting this?  Does it give any indication of which model type, or which model in particular, would be best?  I'm not sure what the clear takeaways are, or whether I should be exploring anything differently in order to guide model selection.  A best-guess takeaway is below.\n",
    "</mark>\n",
    "\n",
    "As shown in the charts above, there is quite a bit of overlap in the Clapper and King data points.  Since parametric models such as Linear and Quadratic Discriminant Analysis and Logistic Regression depend on the data to follow a limited (fixed) parameter function, it's probable that those models will have a difficult time with the classification.  However, non-parametric models such K-Nearest Neighbors and Support Vector Machines that make no assumptions on the functional form of the data may be able to find a wide range of patterns to help aid a successful classification.  Let's get to it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not a huge variation in the range of the numeric values for the parameters, it' still a good idea to normalize the data.  \n",
    "We will use a standard scaler for normalization, where `new_value = (orig_value - mean) / std-dev`.  \n",
    "\n",
    "**Note: This scaling was not done during the original study and may help with yielding improved results.**\n",
    "\n",
    "In addition, let's extract the features and target into generic X and y variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = pd.DataFrame(scaler.fit_transform(rails_df.drop('Species', axis=1)), columns=rails_df.drop('Species', axis=1).columns)\n",
    "# X = rails_df.drop('Species', axis=1)\n",
    "y = rails_df['Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Split the data into test and train datasets, with 30% reserved for testing.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Import the methods we will use for model evaluation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score, roc_curve, auc\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "plt.style.use('default')\n",
    "pd.options.display.float_format = '{:,.3f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Overview\n",
    "We will use the same scoring metrics used in the original study.  Specifically, we will track...\n",
    " - **Accuracy**: the ratio of correctly predicted observations to the total observations.  `(TP + TN) / (TP + FP + TN + FN)`\n",
    " - **Precision**: the ratio of correctly predicted positive observations to the total predicted positive observations.  `TP / (TP + FP)`\n",
    " - **Sensitivity**: the ratio of correctly predicted positive observations to the total actual positive observations.  `TP / (TP + FN)`\n",
    " - **Specificity**: the ratio of correctly predicted negative observations to the total actual negative observations.  `TN / (TN + FP)`\n",
    " - **Area Under the Curve (AUC)**: estimated area under the `ROC curve`.  Used as a general measure of aggregated classification performance. \n",
    " - **Cohen's kappa (*K*)**: similar to Accuracy, but takes into account the possibility of the classification happening by chance.\n",
    "\n",
    "Reference Notes:  \n",
    " - `TP`: True Positive (correctly classified a Clapper rail as a Clapper rail)\n",
    " - `TN`: True Negative (correctly classified a King rail as a King rail)\n",
    " - `FP`: False Positive, Type I error (incorrectly classified a King rail as a Clapper rail)\n",
    " - `FN`: False Negative, Type II error (incorrectly classified a Clapper rail as a King rail)\n",
    " - `TPR`: True Positive Rate (the ratio of True Positives (`TP`) to the total actual positive observations; equal to Sensitivity)\n",
    " - `FPR`: False Positive Rate (the ratio of False Positives (`FP`) to the total actual negative observations; equal to 1 - Specificity)\n",
    " - `ROC curve`: graphical plot of the True Positive Rate (`TPR`) against the False Positive Rate (`FPR`) at various threshold settings (ranging 0.0 - 1.0)\n",
    "<br><br>\n",
    " - Sensitivity is equal to the Recall of the positive class (Clapper)  \n",
    " - Specificity is equal to the Recall of the negative class (King)  \n",
    "\n",
    "The outcomes from the original study are shown in the image below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](orig_outcomes.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parametric Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Linear Discriminant Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "## LDR\n",
    "ldr = LinearDiscriminantAnalysis()\n",
    "ldr.fit(X_train,y_train)\n",
    "\n",
    "# Training summary\n",
    "print(\"Training Score:\", round(ldr.score(X_train, y_train),3))\n",
    "print(\"Coefficients:\", ldr.coef_)\n",
    "print(\"Intercept:\", ldr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pedictions\n",
    "predictions = ldr.predict(X_test)\n",
    "\n",
    "# Get predicted probabilities\n",
    "# Although Clapper is the positive class, it's the first class returned by predict_proba\n",
    "y_pred_proba = ldr.predict_proba(X_test)\n",
    "y_pred_proba_Clapper = ldr.predict_proba(X_test)[::,0]\n",
    "y_pred_proba_King = ldr.predict_proba(X_test)[::,1]\n",
    "\n",
    "# Calculate scores\n",
    "class_rpt = classification_report(y_test, predictions, digits=3, output_dict=True)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,  y_pred_proba_Clapper, pos_label='Clapper')\n",
    "scr_accuracy = round(class_rpt['accuracy'],3)\n",
    "scr_precision = round(class_rpt['Clapper']['precision'],3)\n",
    "scr_sensitivity = round(class_rpt['Clapper']['recall'], 3)\n",
    "scr_specificity = round(class_rpt['King']['recall'], 3)\n",
    "scr_auc = round(auc(fpr, tpr), 3)\n",
    "scr_k = round(cohen_kappa_score(y_test, predictions), 3)\n",
    "\n",
    "print(\"Alt AUC:\", scr_auc_alt)\n",
    "\n",
    "results_cols = ['Class', 'Accuracy', 'Precision', 'Sensitivity', 'Specificity', 'AUC', 'K']\n",
    "ldr_results = pd.DataFrame(columns=results_cols)\n",
    "ldr_results.loc['Linear DFA'] = ['N', scr_accuracy, scr_precision, scr_sensitivity, scr_specificity, scr_auc, scr_k]\n",
    "display(ldr_results)\n",
    "\n",
    "# Display charts\n",
    "fig, axes = plt.subplots(2 ,figsize=(5,8))\n",
    "fig.tight_layout(h_pad=5, w_pad=5)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix= cm, display_labels=ldr.classes_)\n",
    "disp.plot(ax=axes[0])\n",
    "axes[1].plot(fpr,tpr,label=\"LDR AUC=\"+'{:.3f}'.format(scr_auc))\n",
    "axes[1].plot([0, 1], [0, 1],linestyle='dashed', color='gray', label=\"Random classifier\")\n",
    "axes[1].set_xlabel('False Positive Rate (FPR)')\n",
    "axes[1].set_ylabel('True Positive Rate (TPR)')\n",
    "plt.legend(loc=4)\n",
    "'';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Quadratic Discriminant Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "## QDR\n",
    "qdr = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "qdr.fit(X_train,y_train)\n",
    "\n",
    "# Training summary\n",
    "print(\"Training Score:\", round(qdr.score(X_train, y_train),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = qdr.predict(X_test)\n",
    "\n",
    "# Get predicted probabilities\n",
    "# Although Clapper is the positive class, it's the first class returned by predict_proba\n",
    "y_pred_proba = qdr.predict_proba(X_test)\n",
    "y_pred_proba_Clapper = qdr.predict_proba(X_test)[::,0]\n",
    "y_pred_proba_King = qdr.predict_proba(X_test)[::,1]\n",
    "\n",
    "# Calculate scores\n",
    "class_rpt = classification_report(y_test, predictions, digits=3, output_dict=True)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,  y_pred_proba_Clapper, pos_label='Clapper')\n",
    "scr_accuracy = round(class_rpt['accuracy'],3)\n",
    "scr_precision = round(class_rpt['Clapper']['precision'],3)\n",
    "scr_sensitivity = round(class_rpt['Clapper']['recall'], 3)\n",
    "scr_specificity = round(class_rpt['King']['recall'], 3)\n",
    "scr_auc = round(auc(fpr, tpr), 3)\n",
    "scr_k = round(cohen_kappa_score(y_test, predictions), 3)\n",
    "\n",
    "results_cols = ['Class', 'Accuracy', 'Precision', 'Sensitivity', 'Specificity', 'AUC', 'K']\n",
    "qdr_results = pd.DataFrame(columns=results_cols)\n",
    "qdr_results.loc['Quadratic DFA'] = ['N', scr_accuracy, scr_precision, scr_sensitivity, scr_specificity, scr_auc, scr_k]\n",
    "display(qdr_results)\n",
    "\n",
    "# Make charts\n",
    "fig, axes = plt.subplots(2 ,figsize=(5,8))\n",
    "fig.tight_layout(h_pad=5, w_pad=5)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix= cm, display_labels=qdr.classes_)\n",
    "disp.plot(ax=axes[0])\n",
    "axes[1].plot(fpr,tpr,label=\"QDR AUC=\"+'{:.3f}'.format(scr_auc))\n",
    "axes[1].plot([0, 1], [0, 1],linestyle='dashed', color='gray', label=\"Random classifier\")\n",
    "axes[1].set_xlabel('False Positive Rate (FPR)')\n",
    "axes[1].set_ylabel('True Positive Rate (TPR)')\n",
    "plt.legend(loc=4)\n",
    "'';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Logistic Regression\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Training summary\n",
    "print(\"Training Score:\", round(lr.score(X_train, y_train),3))\n",
    "print(\"Coefficients:\", lr.coef_)\n",
    "print(\"Intercept:\", lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "# Get predicted probabilities\n",
    "# Although Clapper is the positive class, it's the first class returned by predict_proba\n",
    "y_pred_proba = lr.predict_proba(X_test)\n",
    "y_pred_proba_Clapper = lr.predict_proba(X_test)[::,0]\n",
    "y_pred_proba_King = lr.predict_proba(X_test)[::,1]\n",
    "\n",
    "# Calculate scores\n",
    "class_rpt = classification_report(y_test, predictions, digits=3, output_dict=True)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,  y_pred_proba_Clapper, pos_label='Clapper')\n",
    "scr_accuracy = round(class_rpt['accuracy'],3)\n",
    "scr_precision = round(class_rpt['Clapper']['precision'],3)\n",
    "scr_sensitivity = round(class_rpt['Clapper']['recall'], 3)\n",
    "scr_specificity = round(class_rpt['King']['recall'], 3)\n",
    "scr_auc = round(auc(fpr, tpr), 3)\n",
    "scr_k = round(cohen_kappa_score(y_test, predictions), 3)\n",
    "\n",
    "results_cols = ['Class', 'Accuracy', 'Precision', 'Sensitivity', 'Specificity', 'AUC', 'K']\n",
    "lr_results = pd.DataFrame(columns=results_cols)\n",
    "lr_results.loc['Logistic Regression'] = ['N', scr_accuracy, scr_precision, scr_sensitivity, scr_specificity, scr_auc, scr_k]\n",
    "display(lr_results)\n",
    "\n",
    "# Make charts\n",
    "fig, axes = plt.subplots(2 ,figsize=(5,8))\n",
    "fig.tight_layout(h_pad=5, w_pad=5)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix= cm, display_labels=lr.classes_)\n",
    "disp.plot(ax=axes[0])\n",
    "axes[1].plot(fpr,tpr,label=\"LR AUC=\"+'{:.3f}'.format(scr_auc))\n",
    "axes[1].plot([0, 1], [0, 1],linestyle='dashed', color='gray', label=\"Random classifier\")\n",
    "axes[1].set_xlabel('False Positive Rate (FPR)')\n",
    "axes[1].set_ylabel('True Positive Rate (TPR)')\n",
    "plt.legend(loc=4)\n",
    "'';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.concat([ldr_results, qdr_results, lr_results]).sort_values(by='Accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parametric CV Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, LeaveOneOut, KFold\n",
    "\n",
    "## LDR\n",
    "ldr_cv = LinearDiscriminantAnalysis()\n",
    "precision_scorer = make_scorer(precision_score, pos_label='Clapper')\n",
    "sensitivity_scorer = make_scorer(recall_score, pos_label='Clapper')\n",
    "specificity_scorer = make_scorer(recall_score, pos_label='King')\n",
    "# auc_scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "k_scorer = make_scorer(cohen_kappa_score)\n",
    "scoring = {'accuracy': 'accuracy',\n",
    "            'precision': precision_scorer,\n",
    "            'sensitivity': sensitivity_scorer,\n",
    "            'specificity': specificity_scorer,\n",
    "            'auc': 'roc_auc',\n",
    "            'k': k_scorer}\n",
    "\n",
    "# loo = LeaveOneOut()\n",
    "# kfold = KFold(n_splits=10, shuffle=True, random_state=77)\n",
    "scores = cross_validate(ldr_cv, X, y, scoring=scoring, cv=10)\n",
    "scr_accuracy = round(scores['test_accuracy'].mean(), 3)\n",
    "scr_precision = round(scores['test_precision'].mean(), 3)\n",
    "scr_sensitivity = round(scores['test_sensitivity'].mean(), 3)\n",
    "scr_specificity = round(scores['test_specificity'].mean(), 3)\n",
    "scr_auc = round(scores['test_auc'].mean(), 3)\n",
    "scr_k = round(scores['test_k'].mean(), 3)\n",
    "\n",
    "\n",
    "results_cols = ['Class', 'Accuracy', 'Precision', 'Sensitivity', 'Specificity', 'AUC', 'K']\n",
    "ldrcv_results = pd.DataFrame(columns=results_cols)\n",
    "ldrcv_results.loc['Linear DFA - CV'] = ['N', scr_accuracy, scr_precision, scr_sensitivity, scr_specificity, scr_auc, scr_k]\n",
    "display(ldrcv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.concat([ldr_results, qdr_results, lr_results, ldrcv_results]).sort_values(by='Accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Parametric Models"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7bea88ec309c8a5ffe0351500cb6c625ab7a852454a42d3f199f784ff5f9460f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('rails': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
